import curl_cffi.requests as requests
from bs4 import BeautifulSoup
import json
import re
import pandas as pd
from datetime import datetime
from urllib.parse import urljoin
import time

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
PROXY = "http://5ZT0gXJzXALl:1eJvGY40@pool.proxy.market:10000"
PROXIES = {"http": PROXY, "https": PROXY}

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.7499.193 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br, zstd",
    "Referer": "https://www.cian.ru/",
    "Sec-Ch-Ua": '"Google Chrome";v="143", "Chromium";v="143", "Not?A_Brand";v="24"',
    "Sec-Ch-Ua-Mobile": "?0",
    "Sec-Ch-Ua-Platform": '"Windows"',
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "same-origin",
    "Upgrade-Insecure-Requests": "1",
}

# ===== –§–£–ù–ö–¶–ò–ò =====

def parse_cian_card(card):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É –∫–∞—Ä—Ç–æ—á–∫—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¶–∏–∞–Ω–∞"""
    result = {
        'id': '',
        'title': '',
        'price': '',
        'price_rub': 0,
        'address': '',
        'area': '',
        'area_m2': 0,
        'rooms': '',
        'floor': '',
        'total_floors': '',
        'description': '',
        'link': '',
        'metro': '',
        'district': '',
        'agency': '',
        'parsed_time': datetime.now().isoformat()
    }
    
    try:
        # ID –∏–∑ data-id –∏–ª–∏ —Å—Å—ã–ª–∫–∏
        if card.get('data-id'):
            result['id'] = card['data-id']
        
        # –°—Å—ã–ª–∫–∞ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
        link_elem = card.find('a', href=re.compile(r'/rent/flat/\d+/'))
        if link_elem:
            href = link_elem.get('href', '')
            result['link'] = urljoin('https://cian.ru', href)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Å—Å—ã–ª–∫–∏
            match = re.search(r'/(\d+)/', href)
            if match:
                result['id'] = match.group(1)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = card.find(['span', 'div'], attrs={'data-mark': 'OfferTitle'})
        if not title_elem:
            title_elem = card.find(['h3', 'h2', 'span'], class_=re.compile(r'title|header', re.I))
        if title_elem:
            result['title'] = title_elem.get_text(strip=True)
        
        # –¶–µ–Ω–∞
        price_elem = card.find(['span', 'div'], attrs={'data-mark': 'MainPrice'})
        if not price_elem:
            # –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É —Å —Å–∏–º–≤–æ–ª–æ–º —Ä—É–±–ª—è
            price_text = card.find(string=re.compile(r'‚ÇΩ'))
            if price_text:
                result['price'] = price_text.strip()
            else:
                # –ò—â–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º
                price_elem = card.find(['span', 'div'], class_=re.compile(r'price|Price|mainPrice', re.I))
        
        if price_elem:
            result['price'] = price_elem.get_text(strip=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã
        if result['price']:
            match = re.search(r'(\d[\d\s]+)', result['price'].replace(' ', ''))
            if match:
                try:
                    result['price_rub'] = int(match.group(1).replace(' ', ''))
                except:
                    pass
        
        # –ê–¥—Ä–µ—Å
        address_elem = card.find(['div', 'span'], attrs={'data-name': 'AddressContainer'})
        if not address_elem:
            address_elem = card.find(['div', 'span'], class_=re.compile(r'address|geo|location', re.I))
        if address_elem:
            result['address'] = address_elem.get_text(' ', strip=True)
        
        # –ú–µ—Ç—Ä–æ –∏ —Ä–∞–π–æ–Ω
        metro_elem = card.find(['div', 'span'], class_=re.compile(r'metro|underground', re.I))
        if metro_elem:
            result['metro'] = metro_elem.get_text(strip=True)
        
        district_elem = card.find(['div', 'span'], class_=re.compile(r'district|region', re.I))
        if district_elem:
            result['district'] = district_elem.get_text(strip=True)
        
        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–ø–ª–æ—â–∞–¥—å, —ç—Ç–∞–∂, –∫–æ–º–Ω–∞—Ç—ã)
        features_container = card.find('div', attrs={'data-name': 'OfferSpec'})
        if not features_container:
            features_container = card.find('div', class_=re.compile(r'features|specs|info', re.I))
        
        if features_container:
            features_text = features_container.get_text(' ', strip=True)
            result['description'] = features_text[:200]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–æ—â–∞–¥—å
            area_match = re.search(r'(\d+[,.]?\d*)\s*–º[¬≤2]', features_text)
            if area_match:
                result['area'] = area_match.group(0)
                try:
                    result['area_m2'] = float(area_match.group(1).replace(',', '.'))
                except:
                    pass
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç—Ç–∞–∂–∏
            floor_match = re.search(r'(\d+)\s*/\s*(\d+)\s*—ç—Ç', features_text)
            if floor_match:
                result['floor'] = floor_match.group(1)
                result['total_floors'] = floor_match.group(2)
            
            # –ö–æ–º–Ω–∞—Ç—ã
            rooms_match = re.search(r'(\d+)-?(–∫–æ–º–Ω|–∫)', features_text, re.I)
            if rooms_match:
                result['rooms'] = rooms_match.group(0)
        
        # –ê–≥–µ–Ω—Ç—Å—Ç–≤–æ
        agency_elem = card.find(['div', 'span'], class_=re.compile(r'agency|realtor|company', re.I))
        if agency_elem:
            result['agency'] = agency_elem.get_text(strip=True)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–ª–æ—â–∞–¥—å –≤ –æ–ø–∏—Å–∞–Ω–∏–∏, –∏—â–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
        if not result['area']:
            area_elem = card.find(string=re.compile(r'–º[¬≤2]'))
            if area_elem:
                result['area'] = area_elem.strip()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
    
    return result

def parse_cian_page(url, page_num=1):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –¶–∏–∞–Ω–∞"""
    print(f"\nüìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: {url[:80]}...")
    
    try:
        response = requests.get(
            url,
            headers=HEADERS,
            proxies=PROXIES,
            timeout=15,
            impersonate="chrome110"
        )
        
        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞ {response.status_code}")
            return []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –ò—â–µ–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        cards = soup.find_all(['article', 'div'], attrs={'data-name': 'CardComponent'})
        if not cards:
            cards = soup.find_all('div', attrs={'data-testid': 'offer-card'})
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫: {len(cards)}")
        
        offers = []
        for i, card in enumerate(cards[:30]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 30 –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            offer = parse_cian_card(card)
            if offer.get('id'):
                offers.append(offer)
                if i < 3:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                    print(f"   {i+1}. ID {offer['id']}: {offer.get('title', '')[:40]}... - {offer.get('price', '')}")
        
        return offers
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return []

def parse_multiple_pages(base_url, max_pages=3):
    """–ü–∞—Ä—Å–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¶–∏–∞–Ω–∞"""
    all_offers = []
    
    for page in range(1, max_pages + 1):
        if page == 1:
            url = base_url
        else:
            url = f"{base_url}&p={page}"
        
        offers = parse_cian_page(url, page)
        all_offers.extend(offers)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
        if page < max_pages and offers:
            delay = 3
            print(f"   ‚è≥ –ñ–¥–µ–º {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π...")
            time.sleep(delay)
    
    return all_offers

def save_results(offers, filename_prefix="cian_offers"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON –∏ CSV"""
    if not offers:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # JSON
    json_filename = f"{filename_prefix}_{timestamp}.json"
    with open(json_filename, "w", encoding="utf-8") as f:
        json.dump(offers, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ JSON: {json_filename}")
    
    # CSV
    csv_filename = f"{filename_prefix}_{timestamp}.csv"
    df = pd.DataFrame(offers)
    
    # –í—ã–±–∏—Ä–∞–µ–º –≤–∞–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    important_cols = ['id', 'title', 'price', 'price_rub', 'area', 'area_m2', 
                     'rooms', 'floor', 'address', 'metro', 'link']
    available_cols = [col for col in important_cols if col in df.columns]
    
    if available_cols:
        df[available_cols].to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ CSV: {csv_filename}")
    else:
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ CSV (–≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏): {csv_filename}")
    
    return json_filename, csv_filename

def analyze_results(offers):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    if not offers:
        return
    
    df = pd.DataFrame(offers)
    
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    print(f"   –í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(offers)}")
    
    if 'price_rub' in df.columns:
        avg_price = df['price_rub'].mean()
        min_price = df['price_rub'].min()
        max_price = df['price_rub'].max()
        print(f"   –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {avg_price:,.0f} ‚ÇΩ")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {min_price:,.0f} ‚ÇΩ")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {max_price:,.0f} ‚ÇΩ")
    
    if 'area_m2' in df.columns:
        avg_area = df['area_m2'].mean()
        print(f"   –°—Ä–µ–¥–Ω—è—è –ø–ª–æ—â–∞–¥—å: {avg_area:.1f} –º¬≤")
    
    if 'rooms' in df.columns:
        room_counts = df['rooms'].value_counts()
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–º–Ω–∞—Ç–∞–º:")
        for rooms, count in room_counts.head().items():
            print(f"     {rooms}: {count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    print(f"\nüéØ –ü–†–ò–ú–ï–†–´ –û–ë–™–Ø–í–õ–ï–ù–ò–ô:")
    for i, offer in enumerate(offers[:3]):
        print(f"\n{i+1}. {offer.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:60]}...")
        print(f"   –¶–µ–Ω–∞: {offer.get('price', '–ù–µ—Ç')}")
        print(f"   –ü–ª–æ—â–∞–¥—å: {offer.get('area', '–ù–µ—Ç')}")
        print(f"   –ê–¥—Ä–µ—Å: {offer.get('address', '–ù–µ—Ç')[:50]}...")
        print(f"   –°—Å—ã–ª–∫–∞: {offer.get('link', '–ù–µ—Ç')[:80]}...")

# ===== –û–°–ù–û–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê =====

def main():
    print("=" * 60)
    print("üè† –ü–ê–†–°–ï–† –¶–ò–ê–ù–ê –° curl_cffi –ò –†–û–¢–ò–†–£–Æ–©–ò–ú –ü–†–û–ö–°–ò")
    print("=" * 60)
    
    # –ë–∞–∑–æ–≤—ã–π URL (–∞—Ä–µ–Ω–¥–∞ –∫–≤–∞—Ä—Ç–∏—Ä –≤ –ú–æ—Å–∫–≤–µ)
    BASE_URL = "https://www.cian.ru/cat.php?deal_type=rent&engine_version=2&offer_type=flat&region=1&type=4"
    
    print(f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...")
    print(f"üì° –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: pool.proxy.market:10000")
    print(f"üîÑ –†–æ—Ç–∞—Ü–∏—è: 5 –º–∏–Ω—É—Ç")
    
    # –ü–∞—Ä—Å–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    offers = parse_multiple_pages(BASE_URL, max_pages=2)
    
    if offers:
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(offers)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        json_file, csv_file = save_results(offers)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        analyze_results(offers)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
        print(f"   JSON: {json_file}")
        print(f"   CSV: {csv_file}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
    
    print("\n" + "=" * 60)
    print("üéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("=" * 60)

if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ:
    # pip install curl_cffi beautifulsoup4 pandas
    
    main()